---
title: "Replication of Study "Recognizing Emotions in a Foreign Language" by Marc D. Pell, Laura Monetta, Silke Paulmann, Sonja A. Kotz (2009, Journal of Nonverbal Behaviors)"
author: "Yuka Tatsumi (ytatsumi@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

instructions---[No abstract is needed.]  Each replication project will have a straightforward, no frills report of the study and results.
 These reports will be publicly available as supplementary material for the aggregate report(s) of the project as a whole. 
 Also, to maximize project integrity, the intro and methods will be written and critiqued in advance of data collection. 
  Introductions can be just 1-2 paragraphs clarifying the main idea of the original study, 
  the target finding for replication, 
  and any other essential information.  
  NO literature review.  
  write both the intro and the methods in past tense.  

Conveying and recognizing emotions is an integral part of human communication. Psychologists have 
been researching on this matter cross-cultrally to explore human's ability in recognizing displays
independent of cuture and learning, however mainly from facial expression, while not so much in vocal emotion. 
Given this, Pell et al. (2009) explores the "universality" of emotion recognition in human speech.

They investigated whether Argentine Spanish speakers can recognize speaker emotions in foreign lanuguages: English, German, and Arabic,
 in addition to their native language Argentine Spanish. 
 The stimuli they heard were all in psuedo-sentences, 
 which were validated by native speakers that they successfully display the intended emotion.
 The task was very simple-- they heard each audio item, and gussed the intended emotion from 7 choices: anger (enojo), disgust (repugnancia), fear (miedo), sadness (tristeza), joy (alegrıa), and neutral (neutralidad).
 Results showed that overall each emotion was recognized accurately: 64% in Spanish, 59% in Arabic, 58% in English, and 56% in German.
 Also, using ANOVA and post hoc Tukey's comparisions, 
 they showed that the participants performed significantly better in their native language than each of the other lanugages, which suggests the "in-group advantage" of emotional recognition.
Regarding the emotion difference, although there was no overall significant difference, they found interactions with language--
 "joy" items were recognized significantly more accurately in Spanish (89%) than in Arabic (59%) or German (57%), both of which also outperformed English (32%).
"Anger" was recognized more accurately in Spanish (81%) and German (77%) than in English (67%) or Arabic (66%).
"Sadness" was recognized with the least accuracy in Spanish (51%) which differed significantly from Arabic (77%), English (74%), and German (65%).
These interaction patterns in Anger and Sad align very closely with the reported accuracy of emotion recognition by native speakers for each language set, which may suggest that 
these effects are item-dependent. 

In the present replication study, I aim to mainly replicate the universality and the in-group advantage of the emotion recognition, using different datasets and participants. 


## Methods

### Power Analysis

<instructions>
Original effect size, 
power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size.
Considerations of feasibility for selecting planned sample size.

- they do not directly report Cohen's d, but report F-values: 
-- 4 x 5 ANOVA, main effect of language on vocal emotion recognition scores, F(3, 180) = 7.49, p < .0001.
-- a significant main effect for emotion, F(4, 240) = 63.59, p < .0001, and a significant interaction of Language X Emotion, F(12, 720) = 39.65, p < .0001.
-- focusing on the main effect for emotion, Eta2 (partial) is 0.515. eta2_to_f2(0.515) >> 1.061856.  
-- pwr.f2.test(u = 5, f2 = 1.061856, sig.level = 0.05, power = 0.8) --> this suggest that I need 12.4833 people.
-- focusing on the main effect for language, Eta2 (partial) is 0.515. eta2_to_f2(0.111) >  0.1248594
-- pwr.f2.test(u = 3, f2 = 0.1248594, sig.level = 0.05, power = 0.80)  --> this suggest that I need 87.3 people.   


### Planned Sample

<instructions>
Planned sample size and/or termination rule, sampling frame, known demographics if any, preselection rules if any.

Participants will be recruited from Prolifics.
They are preselected by their language background: English native speaker, currently physically living in US, no more than 2 years of Spanish, no/minimal exposure to any other languages other than English, including no exposures to entertianments, such as non-English games, songs, shows, animations, that involves exposures to its spoken languages.

Given the power analyses, I plan to aim for 90 sample size. 
Study termination will be to stop at n = 100; the buffer is coming from data drop in case participants did show descripancies in the self-reported language background and Prolific profiles, which happen a lot on Prolific.
If participants failed in attention checks within the study, they will be immidiately exited and its data is xcluded from the study. Compensation will be paid only upto that time.



### Materials

<instructions>
All materials - can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article.

I will use completely different datasets from the original articles.
The test languages are:
- Canadian French
- Japanese
- Thai 
- Greek
The materials for each language are all open source that is either downloadable freely or access by request.
Here is the article for each source:
- CaFE: Gournay, P., Lahaie, O., & Lefebvre, R. (2018, June). A canadian french emotional speech dataset. In Proceedings of the 9th ACM multimedia systems conference (pp. 399-402).
- HCUDB2: Hiroshima City University (2024): Hiroshima City University Japanese Emotional Speech Corpus (HCUDB). Speech Resources Consortium, National Institute of Informatics. (dataset). https://doi.org/10.32130/src.HCUDB
- THAI SER: AIResearch, VISTEC, depa, and Chulalongkorn University (2021). THAI-SER Dataset, Version 2.0. Creative Commons BY-SA 4.0.
- AESDD: Vryzas, N., Kotsakis, R., Liatsou, A., Dimoulas, C. A., & Kalliris, G. (2018). Speech emotion recognition for performance interaction. Journal of the Audio Engineering Society, 66(6), 457-467.


### Procedure	

<instructions>
Can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article.

After participants provide informed consent, they will receive an introduction to the task and instructions. 
Next, they will complete an audio check and a short practice trial to familiarize themselves with the format.
The main trails start after this. For each trial, they will hear an audio clip once and judge the expressed emotion, 
selecting from the following options: happy, sad, angry, fearful, neutral, or surprised. The stimulus set will vary across emotional category
(primarily happiness, anger, and sadness; others are fillers), language (4 languages), speaker (2 females, 2 males), and sentence (3 sentences),
with each clip lasting approximately 4 seconds. Attention checks will be embedded; participants who fail these checks will have their session
terminated right away, and compensation will be prorated based on time completed. 

After the main task, participants will complete a brief questionnaire to confirm their background information (including language history) to ensure data quality. 
Compensation will be approximately $13 per hour. Each session will last approximately 40 minutes. 



### Analysis Plan

Can also quote directly, though it is less often spelled out effectively for an analysis strategy section. 
 The key is to report an analysis strategy that is as close to the original - data cleaning rules, data exclusion rules, covariates, etc. - as possible.  

**Clarify key analysis of interest here**  You can also pre-specify additional analyses you plan to do.



### Differences from Original Study

Explicitly describe known differences in sample, setting, procedure, and analysis plan from original study.  The goal, of course, is to minimize those differences, but differences will inevitably occur.  Also, note whether such differences are anticipated to make a difference based on claims in the original article or subsequent published research on the conditions for obtaining the effect.






### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.


#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan



#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


## Results


### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
### Data Preparation

#### Load Relevant Libraries and Functions

#### Import data

#### Data exclusion / filtering

#### Prepare data for analysis - create columns etc.
```

### Confirmatory analysis

The analyses as specified in the analysis plan.  

*Side-by-side graph with original graph is ideal here*

### Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
